### 트래픽 증가에 대처하는 방법
- scale-up : 서버가 빠르게 응답하도록 하드웨어의 성능을 올리는 방법
- scale-out : 여러 대의 서버가 일을 나눠서 하는 방법
  - 장점1) 하드웨어 향상 비용보다 서버를 추가하는 비용이 더 저렴
  - 장점2) 서버가 여러대 있으면 서버 1대의 장애가 발생하여도 계속 서비스를 제공할 수 있음

### 로드 밸런싱
- 여러 대의 서버로 트래픽을 균등하게 분산시키는 서비스
- scale-out 방식으로 트래픽에 대처하는 경우 로드 밸런싱이 꼭 필요함

### 로드 밸런싱 동작 방식


### 로드 밸런서
- 로드 밸런싱을 담당하는 하드웨어 또는 소프트웨어
- OSI 7계층을 기준으로 어떻게 분산하는지에 따라 종류가 나뉨 (L2, L3, L4, L7 로드 밸런서)
- 상위(하위) 계층으로 갈수록 섬세한(간단한) 로드 밸런싱이 가능하지만 가격이 비쌈(저렴)
- L4 로드 밸런서
  - 전송 계층(L4)의 정보 (IP주소, 포트번호, MAC주소, 전송 프로토콜)를 바탕으로 부하를 분산 
- L7 로드 밸런서

### 로드 밸런서가 서버를 선택하는 방법
- 여러 대의 서버에 트래픽을 어떤 기준으로 분산시키는가
1. 라운드로빈
    - 서버에 들어온 요청을 순서대로 돌아가면서 배정 (첫번째 요청은 첫번째 서버가!)
    - 여러 대의 서버의 성능이 동일하고 처리 시간이 짧은 어플리케이션인 경우 균일하게 분산이 이루어짐
    - 서버의 처리와 관계없이 연결이 할당되기 때문에 세션 유지 기능이 필요한 어플리케이션은 적절하지 않음
2. 가중 라운드로빈
    - 각 서버에 가중치를 매기고 가중치가 높은 서버에게 요청을 우선적으로 배정
    - 서버의 트래픽 처리 능력이 서로 다른 경우 적합
3. IP 해시
    - 클라이언트의 IP주소를 특정 서버로 맵핑하여 요청을 처리
    - 사용자가 항상 동일한 서버에 연결되는 것을 보장
4. 최소 연결 방식
    - 요청이 들어온 시점에 가장 적은 연결 상태를 보이는 서버에게 배정
    - 서버에 분배된 트래픽들이 일정하지 않은 경우 적합
    
